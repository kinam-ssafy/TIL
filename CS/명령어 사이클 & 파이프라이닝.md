# 명령어 사이클 & 파이프라이닝 완전 정복 가이드 🚀

## 📖 목차
1. [명령어 사이클 기본 개념](#명령어-사이클-기본-개념)
2. [Fetch-Decode-Execute-Store 상세 분석](#fetch-decode-execute-store-상세-분석)
3. [파이프라이닝 기본 원리](#파이프라이닝-기본-원리)
4. [파이프라인 위험성 (Hazards)](#파이프라인-위험성-hazards)
5. [위험성 해결 방법](#위험성-해결-방법)
6. [고급 파이프라이닝 기법](#고급-파이프라이닝-기법)
7. [실제 프로세서 구현](#실제-프로세서-구현)
8. [성능 분석과 최적화](#성능-분석과-최적화)
9. [실습 및 시뮬레이션](#실습-및-시뮬레이션)

---

## 🔄 명령어 사이클 기본 개념

### 명령어 사이클이란?

**명령어 사이클(Instruction Cycle)**은 CPU가 하나의 명령어를 완전히 처리하는 전체 과정입니다. 모든 프로그램은 이 기본 사이클의 반복으로 실행됨.

```
기본 사이클:
┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐
│  Fetch  │→  │ Decode  │ → │ Execute │ → │  Store  │
│  인출   │    │  해석   │   │  실행   │   │  저장   │
└─────────┘   └─────────┘   └─────────┘   └─────────┘
     ↑                                           ↓
     ←←←←←←←←←← 다음 명령어로 반복 ←←←←←←←←←←←←
```

### 명령어 사이클의 중요성

#### 1. 폰 노이만 구조의 핵심
```
저장 프로그램 개념의 실현:
- 명령어도 데이터처럼 메모리에 저장
- CPU가 순차적으로 명령어 처리
- 프로그램의 자동 실행 가능
```

#### 2. 성능의 기본 단위
```
CPU 성능 = 클록 주파수 × IPC (Instructions Per Clock)
IPC = 1 / CPI (Cycles Per Instruction)

예시:
- 단순 명령어: 1 사이클
- 복잡 명령어: 10-100 사이클
- 메모리 접근: 수백 사이클
```

#### 3. 최적화의 출발점
```
성능 향상 방법:
1. 클록 주파수 증가 (물리적 한계)
2. 명령어당 사이클 수 감소 (파이프라이닝)
3. 사이클당 명령어 수 증가 (슈퍼스칼라)
```

---

## 🔍 Fetch-Decode-Execute-Store 상세 분석

### 1. Fetch (인출) 단계

명령어를 메모리에서 가져오는 단계입니다.

#### 상세 과정
```
1. PC → MAR 복사
   MAR (Memory Address Register) ← PC (Program Counter)
   
2. 메모리 읽기 신호 전송
   Control Bus → READ 신호
   Address Bus → MAR의 주소
   
3. 메모리에서 명령어 읽기
   Memory[MAR] → Data Bus → MDR
   
4. 명령어 레지스터로 복사
   IR (Instruction Register) ← MDR
   
5. PC 증가
   PC ← PC + 명령어_길이
```

#### 인출 단계의 복잡성

**고정 길이 명령어 (RISC)**:
```
ARM 32비트 명령어:
- 모든 명령어가 4바이트
- PC += 4로 간단히 증가
- 인출 과정 단순화

예시: ARM 명령어
ADD R1, R2, R3    ; 32비트 고정
MOV R1, #100      ; 32비트 고정
```

**가변 길이 명령어 (CISC)**:
```
x86 명령어:
- 1바이트 ~ 15바이트까지 가변
- 명령어 해석 후 길이 결정
- 복잡한 디코딩 필요

예시: x86 명령어
NOP               ; 1바이트
MOV EAX, EBX      ; 2바이트
MOV EAX, [EBX+ECX*2+100]  ; 7바이트
```

#### 인출 최적화 기법

**명령어 프리페칭**:
```
기본 인출: 한 번에 하나씩
프리페칭: 미리 여러 개 인출

인출 버퍼:
┌─────────┬─────────┬─────────┬─────────┐
│ 명령어1 │ 명령어2 │ 명령어3 │ 명령어4 │
└─────────┴─────────┴─────────┴─────────┘
      ↑ 현재 실행 중인 명령어
```

**분기 예측과 인출**:
```
순차 인출: PC + 4, PC + 8, PC + 12...
분기 예측: 점프할 가능성이 높은 주소도 미리 인출

예시:
0x1000: CMP R1, 0
0x1004: JE  0x2000     ← 분기 명령어
0x1008: ADD R2, R3     ← 순차 경로
...
0x2000: SUB R4, R5     ← 분기 목적지

분기 예측기가 JE가 실행될 것으로 예측하면
0x2000 주소의 명령어를 미리 인출
```

### 2. Decode (해석) 단계

명령어의 의미를 파악하고 실행 준비를 하는 단계입니다.

#### 명령어 형식 분석

**R-Type (레지스터 타입)**:
```
32비트 MIPS 명령어 예시:
┌──────┬─────┬─────┬─────┬─────┬──────┐
│  op  │ rs  │ rt  │ rd  │shamt│ funct│
│ 6bit │5bit │5bit │5bit │5bit │ 6bit │
└──────┴─────┴─────┴─────┴─────┴──────┘

ADD R1, R2, R3 해석:
- op: 000000 (R-type 표시)
- rs: 00010 (R2, 첫 번째 소스)
- rt: 00011 (R3, 두 번째 소스)  
- rd: 00001 (R1, 목적지)
- funct: 100000 (ADD 연산 코드)
```

**I-Type (즉시값 타입)**:
```
┌──────┬─────┬─────┬─────────────────┐
│  op  │ rs  │ rt  │   immediate     │
│ 6bit │5bit │5bit │     16bit       │
└──────┴─────┴─────┴─────────────────┘

ADDI R1, R2, 100 해석:
- op: 001000 (ADDI)
- rs: 00010 (R2, 베이스 레지스터)
- rt: 00001 (R1, 목적지)
- immediate: 0000000001100100 (100)
```

#### 해석 과정의 단계

```
1. 연산 코드 추출
   opcode = IR[31:26]  (상위 6비트)
   
2. 연산 타입 결정
   switch(opcode) {
       case R_TYPE: decode_r_type();
       case I_TYPE: decode_i_type();
       case J_TYPE: decode_j_type();
   }
   
3. 피연산자 정보 추출
   - 소스 레지스터 번호
   - 목적지 레지스터 번호
   - 즉시값 또는 주소
   
4. 제어 신호 생성
   - ALU 제어 신호
   - 레지스터 쓰기 활성화
   - 메모리 읽기/쓰기 신호
   - 분기 제어 신호
```

#### 복잡 명령어 해석 (x86)

```
x86 명령어는 여러 단계의 해석 필요:

1. 프리픽스 분석 (옵션)
   - 세그먼트 오버라이드
   - 주소/피연산자 크기
   - 반복 프리픽스
   
2. 연산 코드 해석
   - 1-3바이트 가변 길이
   - 이스케이프 시퀀스 처리
   
3. ModR/M 바이트 해석
   - 주소 지정 모드
   - 레지스터 필드
   
4. SIB 바이트 해석 (필요시)
   - 스케일, 인덱스, 베이스
   
5. 변위값 처리 (필요시)
   - 1, 2, 4바이트 변위

예시: MOV EAX, [EBX+ECX*2+100]
┌─────┬─────┬─────┬─────┬─────────┐
│ MOV │ModR/M│ SIB │ Disp32      │
│ 8B  │ 44   │ 4B  │ 00000064    │
└─────┴─────┴─────┴─────────────┘
```

### 3. Execute (실행) 단계

실제 연산을 수행하는 단계입니다.

#### ALU 연산 실행

**산술 연산**:
```
ADD R1, R2, R3 실행:

1. 소스 레지스터 읽기
   operand1 = Register[R2]  // 예: 0x12345678
   operand2 = Register[R3]  // 예: 0x87654321
   
2. ALU에서 덧셈 수행
   result = operand1 + operand2
   result = 0x12345678 + 0x87654321 = 0x99999999
   
3. 플래그 업데이트
   Zero Flag (ZF) = (result == 0) ? 1 : 0     // 0
   Carry Flag (CF) = (overflow occurred) ? 1 : 0  // 0
   Sign Flag (SF) = (result < 0) ? 1 : 0      // 1 (MSB=1)
   Overflow Flag (OF) = (signed overflow) ? 1 : 0 // 0
```

**논리 연산**:
```
AND R1, R2, R3 실행:

operand1 = 0x12345678  (R2)
operand2 = 0x87654321  (R3)

비트별 AND 연산:
  0001 0010 0011 0100 0101 0110 0111 1000
& 1000 0111 0110 0101 0100 0011 0010 0001
  ─────────────────────────────────────────
  0000 0010 0010 0100 0100 0010 0010 0000
  
result = 0x02244220

플래그 업데이트:
ZF = 0 (결과가 0이 아님)
SF = 0 (MSB가 0)
PF = 계산 (패리티 플래그)
```

#### 메모리 접근 연산

**로드 연산 (LW R1, 100(R2))**:
```
1. 주소 계산
   address = Register[R2] + 100
   예: address = 0x10000000 + 100 = 0x10000064
   
2. 메모리 읽기 요청
   MAR ← address
   Control Bus → READ 신호
   
3. 메모리 응답 대기
   Memory[address] → MDR
   예: MDR = 0xABCDEF01
   
4. 결과 준비 (Write-back 단계에서 레지스터에 저장)
   write_data = MDR
   write_register = R1
```

**스토어 연산 (SW R1, 100(R2))**:
```
1. 주소 계산
   address = Register[R2] + 100
   
2. 저장할 데이터 준비
   write_data = Register[R1]
   
3. 메모리 쓰기 요청
   MAR ← address
   MDR ← write_data
   Control Bus → WRITE 신호
```

#### 분기 연산

**조건부 분기 (BEQ R1, R2, label)**:
```
1. 비교 연산
   condition = (Register[R1] == Register[R2])
   
2. 분기 주소 계산
   if (condition) {
       target_address = PC + (offset << 2)
   }
   
3. PC 업데이트 결정
   if (condition) {
       PC ← target_address  (분기 실행)
   } else {
       PC ← PC + 4         (순차 실행)
   }
```

### 4. Store (저장) 단계

연산 결과를 적절한 위치에 저장하는 단계입니다.

#### 레지스터 쓰기
```
ADD R1, R2, R3의 결과 저장:

1. 목적지 레지스터 확인
   destination = R1 (레지스터 번호 1)
   
2. 쓰기 활성화 신호 확인
   RegWrite = 1 (레지스터 쓰기 허용)
   
3. 데이터 쓰기
   Register[1] ← ALU_result
   Register[1] ← 0x99999999
   
4. 레지스터 파일 업데이트 완료
```

#### 메모리 쓰기
```
SW R1, 100(R2)의 실행:

1. 주소와 데이터 확인
   address = MAR에 이미 설정됨
   data = MDR에 이미 설정됨
   
2. 메모리 쓰기 실행
   Memory[address] ← data
   
3. 쓰기 완료 확인
   메모리 컨트롤러의 완료 신호 대기
```

#### 플래그 레지스터 업데이트
```
산술/논리 연산 후:

EFLAGS 레지스터 업데이트:
┌─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┐
│?│?│?│OF│DF│IF│TF│SF│ZF│?│AF│?│PF│?│CF│
└─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┘

각 플래그 업데이트:
CF = 자리올림 발생 여부
PF = 결과의 패리티 (짝수/홀수)
AF = 보조 자리올림 (BCD 연산용)
ZF = 결과가 0인지 여부
SF = 결과의 부호 (MSB)
OF = 부호있는 오버플로우 발생 여부
```

---

## ⚡ 파이프라이닝 기본 원리

### 파이프라이닝이란?

**파이프라이닝(Pipelining)**은 여러 명령어를 동시에 처리하여 전체 처리량을 향상시키는 기법입니다. 마치 공장의 조립라인처럼 각 단계를 병렬로 수행합니다.

#### 현실 비유: 세탁소 예시
```
파이프라이닝 없는 경우 (순차 처리):
시간 1-2: 옷1 세탁
시간 3-4: 옷1 건조  
시간 5-6: 옷1 다림질
시간 7-8: 옷2 세탁
시간 9-10: 옷2 건조
시간 11-12: 옷2 다림질

총 12시간에 2벌 완성 = 6시간/벌

파이프라이닝 적용:
시간 1-2: 옷1 세탁
시간 3-4: 옷1 건조, 옷2 세탁
시간 5-6: 옷1 다림질, 옷2 건조, 옷3 세탁
시간 7-8: 옷2 다림질, 옷3 건조, 옷4 세탁

총 8시간에 4벌 완성 = 2시간/벌 (3배 향상!)
```

### 기본 5단계 파이프라인

```
┌─────────┬─────────┬─────────┬─────────┬─────────┐
│   IF    │   ID    │   EX    │   MEM   │   WB    │
│ Fetch   │ Decode  │ Execute │ Memory  │Write-back
│ 인출    │ 해석    │ 실행    │ 메모리  │ 저장    │
└─────────┴─────────┴─────────┴─────────┴─────────┘

각 단계가 1 클록 사이클 소요한다고 가정
```

#### 단계별 상세 설명

**IF (Instruction Fetch)**:
```
기능: 명령어 인출
동작:
- PC → I-Cache 주소
- I-Cache에서 명령어 읽기  
- PC += 4 (다음 명령어 준비)

하드웨어: 명령어 캐시, PC, 증가기
```

**ID (Instruction Decode)**:
```
기능: 명령어 해석 및 레지스터 읽기
동작:
- 명령어 필드 분해
- 제어 신호 생성
- 레지스터 파일에서 피연산자 읽기
- 즉시값 부호 확장

하드웨어: 해석기, 레지스터 파일, 부호 확장기
```

**EX (Execute)**:
```
기능: 연산 수행
동작:
- ALU 연산 (산술/논리)
- 분기 조건 평가
- 메모리 주소 계산

하드웨어: ALU, 가산기, 비교기
```

**MEM (Memory Access)**:
```
기능: 메모리 접근
동작:
- 로드: 메모리에서 데이터 읽기
- 스토어: 메모리에 데이터 쓰기
- 다른 명령어: 아무 동작 없음

하드웨어: 데이터 캐시, 메모리 컨트롤러
```

**WB (Write Back)**:
```
기능: 결과 저장
동작:
- ALU 결과를 레지스터에 쓰기
- 메모리 로드 데이터를 레지스터에 쓰기

하드웨어: 레지스터 파일 쓰기 포트
```

### 파이프라이닝 실행 예시

#### 5개 명령어의 파이프라인 실행

```
명령어:
I1: ADD R1, R2, R3
I2: SUB R4, R1, R5  
I3: LW  R6, 100(R7)
I4: SW  R6, 200(R8)
I5: BEQ R1, R4, label

시간 순서:
클록 │ IF │ ID │ EX │MEM│ WB │
──────┼────┼────┼────┼───┼────┤
  1   │ I1 │    │    │   │    │
  2   │ I2 │ I1 │    │   │    │
  3   │ I3 │ I2 │ I1 │   │    │
  4   │ I4 │ I3 │ I2 │I1 │    │
  5   │ I5 │ I4 │ I3 │I2 │ I1 │
  6   │    │ I5 │ I4 │I3 │ I2 │
  7   │    │    │ I5 │I4 │ I3 │
  8   │    │    │    │I5 │ I4 │
  9   │    │    │    │   │ I5 │
```

#### 성능 비교

**파이프라이닝 없는 경우**:
```
각 명령어가 5 사이클 소요
5개 명령어 = 5 × 5 = 25 사이클
```

**파이프라이닝 적용**:
```
첫 명령어: 5 사이클 (파이프라인 채우기)
나머지 4개: 각 1 사이클씩
총 5 + 4 = 9 사이클

성능 향상: 25/9 ≈ 2.78배
```

### 이상적 파이프라인의 특성

#### 처리량 (Throughput)
```
이상적 처리량 = 파이프라인 단계 수

5단계 파이프라인의 경우:
- 이론적 최대 5배 성능 향상
- 실제로는 위험성으로 인해 더 낮음
```

#### 지연 시간 (Latency)
```
명령어 지연 시간은 변하지 않음:
- 파이프라이닝 없음: 5 사이클
- 파이프라이닝 적용: 여전히 5 사이클

하지만 전체 처리량은 크게 향상!
```

---

## ⚠️ 파이프라인 위험성 (Hazards)

파이프라인의 이상적 동작을 방해하는 요소들입니다.

### 1. 구조적 위험성 (Structural Hazards)

**정의**: 하드웨어 자원 부족으로 인한 충돌

#### 메모리 접근 충돌
```
문제 상황:
클록 4에서 I1이 MEM 단계 (데이터 메모리 접근)
동시에 I4가 IF 단계 (명령어 메모리 접근)

단일 메모리 사용 시 충돌 발생!

클록 │ IF │ ID │ EX │MEM│ WB │
──────┼────┼────┼────┼───┼────┤
  4   │ I4 │ I3 │ I2 │I1 │    │
      │ ↑  │    │    │↑  │    │
      │메모리│    │    │메모리│    │
      │접근 │    │    │접근 │    │
      └─────충돌!─────┘
```

#### 해결 방법
```
1. 하버드 구조 사용
   - 명령어 메모리와 데이터 메모리 분리
   - I-Cache와 D-Cache 독립적 운영

2. 메모리 뱅킹
   - 여러 메모리 뱅크로 분할
   - 동시 접근 가능

3. 파이프라인 정지 (Stall)
   - 충돌 발생 시 일시 정지
   - 성능 저하 발생
```

#### 레지스터 파일 포트 부족
```
문제: 동시에 여러 레지스터 접근 필요

클록 5에서:
- I2가 WB 단계: R4에 쓰기
- I5가 ID 단계: R1, R4 읽기

필요한 포트: 읽기 2개 + 쓰기 1개 = 3개

해결:
- 멀티포트 레지스터 파일 사용
- 읽기 포트 2개, 쓰기 포트 1개
```

### 2. 데이터 위험성 (Data Hazards)

**정의**: 명령어 간 데이터 의존성으로 인한 문제

#### RAW (Read After Write) 위험성

가장 흔한 데이터 위험성입니다.

```
예시:
I1: ADD R1, R2, R3    # R1에 쓰기
I2: SUB R4, R1, R5    # R1에서 읽기 (의존성!)

문제 분석:
클록 │ IF │ ID │ EX │MEM│ WB │
──────┼────┼────┼────┼───┼────┤
  1   │ I1 │    │    │   │    │
  2   │ I2 │ I1 │    │   │    │
  3   │    │ I2 │ I1 │   │    │
      │    │ ↑  │    │   │    │
      │    │R1읽기│   │   │    │
  4   │    │    │    │I1 │    │
  5   │    │    │    │   │ I1 │
      │    │    │    │   │ ↑  │
      │    │    │    │   │R1쓰기│

I2가 클록 3에서 R1을 읽지만,
I1이 R1에 쓰는 것은 클록 5!
→ 잘못된 값 읽기
```

#### WAR (Write After Read) 위험성

```
예시:
I1: SUB R4, R1, R3    # R1에서 읽기
I2: ADD R1, R2, R3    # R1에 쓰기

이론적 문제:
I2가 I1보다 먼저 R1에 쓰면,
I1이 잘못된 값을 읽을 수 있음

하지만 기본 5단계 파이프라인에서는:
- 읽기: ID 단계 (클록 2)
- 쓰기: WB 단계 (클록 5)
→ 읽기가 항상 먼저 발생하므로 문제없음
```

#### WAW (Write After Write) 위험성

```
예시:
I1: ADD R1, R2, R3    # R1에 쓰기
I2: SUB R1, R4, R5    # R1에 쓰기

문제:
최종적으로 I2의 결과가 R1에 있어야 하는데,
I1이 나중에 쓰면 잘못된 결과

기본 파이프라인에서는 문제없음:
- 모든 쓰기가 WB 단계에서 순서대로 발생
```

### 3. 제어 위험성 (Control Hazards)

**정의**: 분기 명령어로 인한 제어 흐름 변경 문제

#### 분기 명령어의 문제점

```
예시:
0x1000: ADD R1, R2, R3
0x1004: BEQ R1, R0, 0x2000  # 분기 명령어
0x1008: SUB R4, R5, R6      # 다음 명령어 (순차)
0x100C: ...
...
0x2000: MUL R7, R8, R9      # 분기 목적지

문제:
BEQ의 조건 평가는 EX 단계에서 발생 (클록 3)
하지만 그때까지 이미 0x1008, 0x100C 명령어들이
파이프라인에 들어감

만약 분기가 실행되면?
→ 잘못 인출된 명령어들을 모두 취소해야 함
```

#### 분기 지연 (Branch Penalty)

```
분기 명령어 실행 과정:

클록 │ IF │ ID │ EX │MEM│ WB │
──────┼────┼────┼────┼───┼────┤
  1   │BEQ │    │    │   │    │
  2   │SUB │BEQ │    │   │    │  # SUB를 잘못 인출
  3   │MUL │SUB │BEQ │   │    │  # 분기 조건 평가
      │    │    │ ↑  │   │    │  # 분기 실행 결정
  4   │목적지│-- │-- │BEQ│    │  # 잘못된 명령어 취소
  5   │    │목적지│-- │-- │BEQ │
  6   │    │    │목적지│-- │-- │

분기 페널티: 2 사이클 (SUB, MUL 취소)
```

---

## 🛠️ 위험성 해결 방법

### 데이터 위험성 해결

#### 1. 파이프라인 정지 (Pipeline Stall)

**기본 원리**: 의존성이 해결될 때까지 파이프라인을 멈춤

```
RAW 위험성에 대한 정지:

원래 실행:
클록 │ IF │ ID │ EX │MEM│ WB │
──────┼────┼────┼────┼───┼────┤
  1   │ADD │    │    │   │    │
  2   │SUB │ADD │    │   │    │ # SUB가 ADD의 R1 필요
  3   │    │SUB │ADD │   │    │ # 위험성 감지!

정지 적용:
클록 │ IF │ ID │ EX │MEM│ WB │
──────┼────┼────┼────┼───┼────┤
  1   │ADD │    │    │   │    │
  2   │SUB │ADD │    │   │    │
  3   │SUB │stall│ADD │   │    │ # SUB 정지
  4   │SUB │stall│    │ADD│    │ # SUB 계속 정지  
  5   │    │SUB │    │   │ADD │ # 이제 SUB 진행 가능
```

**정지 구현**:
```verilog
// 위험성 감지 유닛
hazard_detection_unit hdu(
    .ID_rs(ID_instruction[25:21]),     // ID 단계 소스 레지스터
    .ID_rt(ID_instruction[20:16]),
    .EX_rd(EX_destination_register),   // EX 단계 목적지 레지스터
    .MEM_rd(MEM_destination_register), // MEM 단계 목적지 레지스터
    .stall(pipeline_stall)             // 정지 신호
);

// 정지 시 동작
if (pipeline_stall) {
    PC_write = 0;        // PC 업데이트 중지
    IF_ID_write = 0;     // IF/ID 레지스터 쓰기 중지
    ID_EX_clear = 1;     // ID/EX 레지스터 클리어 (NOP 삽입)
}
```

#### 2. 전달 (Forwarding/Bypassing)

**기본 원리**: 결과를 기다리지 말고 바로 전달

```
전달 없는 경우:
클록 │ IF │ ID │ EX │MEM│ WB │
──────┼────┼────┼────┼───┼────┤
  1   │ADD │    │    │   │    │
  2   │SUB │ADD │    │   │    │
  3   │    │SUB │ADD │   │    │ # ADD 결과 계산 완료
  4   │    │    │SUB │ADD│    │ # 하지만 WB까지 기다려야 함
  5   │    │    │    │SUB│ADD │ # 드디어 SUB 실행 가능

전달 적용:
클록 │ IF │ ID │ EX │MEM│ WB │
──────┼────┼────┼────┼───┼────┤
  1   │ADD │    │    │   │    │
  2   │SUB │ADD │    │   │    │
  3   │    │SUB │ADD │   │    │
      │    │    │ ↑  │   │    │
      │    │    └──전달───┘    │ # ADD 결과를 바로 SUB에 전달
  4   │    │    │    │SUB│    │ # SUB 정상 실행
```

**전달 경로**:
```
1. EX/MEM → EX (ALU 결과 전달)
   EX 단계 완료 즉시 다음 명령어의 EX 단계로

2. MEM/WB → EX (메모리 로드 결과 전달)  
   MEM 단계 완료 후 다음 명령어의 EX 단계로

3. MEM/WB → ID (레지스터 읽기 전달)
   WB 단계와 동시에 ID 단계로
```

**전달 유닛 구현**:
```verilog
// 전달 조건 확인
forwarding_unit fu(
    .EX_rs(EX_source_reg1),
    .EX_rt(EX_source_reg2),
    .MEM_rd(MEM_destination_reg),
    .WB_rd(WB_destination_reg),
    .MEM_RegWrite(MEM_reg_write_enable),
    .WB_RegWrite(WB_reg_write_enable),
    .ForwardA(forward_A),      // 첫 번째 피연산자 전달
    .ForwardB(forward_B)       // 두 번째 피연산자 전달
);

// 전달 선택
case (forward_A)
    2'b00: ALU_input_A = EX_register_data;  // 정상
    2'b01: ALU_input_A = WB_result;         // WB에서 전달
    2'b10: ALU_input_A = MEM_result;        // MEM에서 전달
endcase
```

#### 3. 로드-사용 위험성 특별 처리

```
특별한 경우: 로드 명령어 직후 사용

I1: LW  R1, 100(R2)   # 메모리에서 로드
I2: ADD R3, R1, R4    # 바로 사용

문제:
LW의 결과는 MEM 단계에서 나옴 (클록 4)
ADD는 EX 단계에서 R1이 필요 (클록 3)
→ 전달로도 해결 불가!

해결: 1 사이클 정지 + 전달
클록 │ IF │ ID │ EX │MEM│ WB │
──────┼────┼────┼────┼───┼────┤
  1   │ LW │    │    │   │    │
  2   │ADD │ LW │    │   │    │
  3   │ADD │stall│ LW │   │    │ # 1 사이클 정지
  4   │    │ADD │    │ LW│    │ # 전달로 해결
      │    │    │    │ ↑ │    │
      │    │    └─────전달────┘
```

### 제어 위험성 해결

#### 1. 분기 예측 (Branch Prediction)

**정적 분기 예측**:
```
1. 항상 taken (분기 실행)
2. 항상 not-taken (분기 실행 안함)
3. BTFN (Backward Taken, Forward Not-taken)
   - 루프 (뒤로 가는 분기): taken
   - 조건문 (앞으로 가는 분기): not-taken
```

**동적 분기 예측**:
```
1비트 예측기:
┌─────────┐ taken    ┌─────────┐
│  Taken  │ ────────→│Not-Taken│
│   (T)   │          │   (NT)  │
└─────────┘ ←──────── └─────────┘
              not-taken

문제: 한 번 틀리면 2번 페널티
예: T-T-T-T-NT-T-T-T-T-NT
마지막 2개에서 모두 예측 실패

2비트 포화 카운터:
      taken        taken
  ┌──────────┐  ┌──────────┐
  │Strongly  │  │ Weakly   │
  │  Taken   │←→│  Taken   │
  │   (11)   │  │   (10)   │
  └──────────┘  └──────────┘
       ↑              ↓
       │not-taken     │taken
       │              │
  ┌──────────┐  ┌──────────┐
  │Strongly  │  │ Weakly   │
  │Not-Taken │←→│Not-Taken │
  │   (00)   │  │   (01)   │
  └──────────┘  └──────────┘
    not-taken      taken

예측: 상위 비트 (1이면 taken, 0이면 not-taken)
```

**분기 예측 버퍼 (Branch Prediction Buffer)**:
```
PC의 하위 비트를 인덱스로 사용:

PC[7:2] │ 예측 비트 │ 대상 주소
────────┼───────────┼──────────
 000000 │    11     │ 0x2000
 000001 │    01     │ 0x3000  
 000010 │    10     │ 0x1500
   ...  │   ...     │  ...

분기 명령어 인출 시:
1. PC로 예측 테이블 검색
2. 예측에 따라 다음 명령어 인출
3. 실제 실행 시 예측 업데이트
```

#### 2. 분기 지연 슬롯 (Branch Delay Slot)

**MIPS의 해결 방법**: 분기 명령어 뒤의 명령어를 항상 실행

```
어셈블리 코드:
    BEQ  R1, R2, target
    ADD  R3, R4, R5        # 지연 슬롯 (항상 실행됨)
    SUB  R6, R7, R8        # 분기 시 실행 안됨
target:
    MUL  R9, R10, R11

실행 순서:
1. BEQ 조건 평가
2. ADD 실행 (분기 결과와 무관)
3. 분기 결과에 따라 SUB 또는 MUL 실행

컴파일러의 역할:
- 유용한 명령어를 지연 슬롯에 배치
- 불가능하면 NOP 삽입
```

#### 3. 다중 분기 예측

**gshare 예측기**:
```
전역 히스토리와 PC를 XOR하여 인덱스 생성

Global History: 10110 (최근 5개 분기 결과)
PC[6:2]:       01100
XOR 결과:      11010 (인덱스)

장점: 분기 간 상관관계 활용
예: if(a > 0) if(b > 0) c++
첫 번째 분기가 taken이면 두 번째도 taken일 가능성 높음
```

**Perceptron 예측기**:
```
기계학습 기반 분기 예측:

y = w0 + w1*h1 + w2*h2 + ... + wn*hn

wi: 가중치 (학습으로 조정)
hi: 히스토리 비트 (+1 또는 -1)
y > 0이면 taken, y ≤ 0이면 not-taken

학습:
if (prediction != actual) {
    if (actual == taken) wi += hi
    else wi -= hi
}
```

---

## 🚀 고급 파이프라이닝 기법

### 슈퍼스칼라 (Superscalar)

**정의**: 한 클록에 여러 명령어를 동시 발행하는 기법

#### 기본 구조
```
2-way 슈퍼스칼라:

           ┌─────┐    ┌─────┐
명령어 → │ IF1 │ → │ ID1 │ → ALU1 → MEM1 → WB1
큐      │     │    │     │
        └─────┘    └─────┘    
           │         │
           ↓         ↓
         ┌─────┐    ┌─────┐
         │ IF2 │ → │ ID2 │ → ALU2 → MEM2 → WB2
         └─────┘    └─────┘

한 클록에 2개 명령어 처리 가능
```

#### 명령어 발행 제약
```
동시 발행 불가능한 경우:

1. 구조적 위험성
   - 같은 기능 단위 필요
   - 예: 두 개의 곱셈 명령어

2. 데이터 의존성  
   - RAW, WAR, WAW 위험성
   - 예: ADD R1, R2, R3
        SUB R4, R1, R5

3. 제어 의존성
   - 분기 명령어와 그 다음 명령어
```

#### 명령어 발행 정책

**순차 발행 (In-order Issue)**:
```
명령어를 프로그램 순서대로만 발행
장점: 간단한 구현
단점: 제한적 병렬성

예시:
I1: ADD R1, R2, R3    # 발행 가능
I2: MUL R4, R5, R6    # 발행 가능 (독립적)
I3: SUB R7, R1, R8    # 발행 불가 (I1 의존성)
I4: OR  R9, R10, R11  # 발행 불가 (순차 발행)

클록 1: I1, I2 발행
클록 2: I3 발행 (I1 완료 후), I4는 대기
```

**비순차 발행 (Out-of-order Issue)**:
```
의존성이 없는 명령어는 순서와 관계없이 발행
장점: 높은 병렬성
단점: 복잡한 구현

예시:
I1: ADD R1, R2, R3    # 발행
I2: MUL R4, R5, R6    # 발행  
I3: SUB R7, R1, R8    # 대기 (I1 의존성)
I4: OR  R9, R10, R11  # 발행 가능! (독립적)

클록 1: I1, I2 발행
클록 2: I4 발행 (I3 건너뛰고), I3은 계속 대기
```

### VLIW (Very Long Instruction Word)

**정의**: 컴파일러가 병렬성을 찾아 긴 명령어로 패킹

#### 기본 개념
```
128비트 VLIW 명령어 (4개 32비트 슬롯):
┌─────────┬─────────┬─────────┬─────────┐
│ ALU 연산│ 로드/스토어│ 분기   │ 곱셈   │
│ 32비트  │ 32비트  │ 32비트  │ 32비트  │
└─────────┴─────────┴─────────┴─────────┘

하나의 명령어로 4개 연산을 동시 실행
```

#### 컴파일러의 역할
```
원래 코드:
a = b + c;      // ADD
d = e * f;      // MUL  
g = mem[h];     // LOAD
if (i == 0) ... // BRANCH

컴파일러 최적화 후:
[ADD a,b,c | MUL d,e,f | LOAD g,h | BRANCH i,label]
하나의 VLIW 명령어로 패킹
```

#### 장단점
```
장점:
- 하드웨어 단순 (의존성 검사 불필요)
- 높은 병렬성 (컴파일러가 최적화)
- 전력 효율적

단점:  
- 컴파일러 복잡성
- 코드 크기 증가 (빈 슬롯)
- 런타임 유연성 부족
```

### 다중 발행 파이프라인

#### Intel Pentium (2-way 슈퍼스칼라)
```
U-파이프: 모든 명령어 실행 가능
V-파이프: 단순 명령어만 실행 가능

동시 실행 가능한 조합:
- 단순 ALU + 단순 ALU
- 단순 ALU + 분기
- 로드 + 단순 ALU

불가능한 조합:
- 복잡 명령어 + 임의 명령어
- 의존성이 있는 명령어들
```

#### Intel Pentium Pro (3-way 슈퍼스칼라)
```
포트 구성:
포트 0: 복잡 ALU, 시프트, 곱셈
포트 1: 단순 ALU, LEA, 분기
포트 2: 로드 연산
포트 3: 스토어 주소 계산  
포트 4: 스토어 데이터

예시 명령어 발행:
클록 1: [포트0: MUL] [포트1: ADD] [포트2: LOAD]
클록 2: [포트0: SHR] [포트1: CMP] [포트4: STORE]
```

---

## 🖥️ 실제 프로세서 구현

### MIPS R4000 파이프라인

#### 8단계 슈퍼파이프라인
```
단계 1-2: IF (명령어 인출)
- 1단계: TLB 접근 및 가상→물리 주소 변환
- 2단계: I-Cache 접근 및 명령어 인출

단계 3: RF (레지스터 파일 접근)  
- 명령어 해석 및 레지스터 읽기

단계 4: EX (실행)
- ALU 연산 수행

단계 5-6: DF (데이터 인출)
- 5단계: TLB 접근 (데이터)
- 6단계: D-Cache 접근

단계 7: DS (데이터 저장)
- 캐시/메모리에 데이터 쓰기

단계 8: WB (되쓰기)
- 레지스터에 결과 저장
```

#### 클록 주파수 vs 파이프라인 깊이
```
R4000 설계 목표:
- 높은 클록 주파수 (100MHz)
- 각 단계를 최대한 단순화
- 단계당 10ns 이하

트레이드오프:
- 깊은 파이프라인 → 높은 클록 주파수
- 하지만 분기 미스 페널티 증가 (8 사이클!)
```

### Intel Pentium 4 파이프라인

#### 31단계 하이퍼파이프라인
```
프론트엔드 (1-8단계):
1-2: Trace Cache Next IP / Trace Cache Fetch
3-4: Drive / Allocation  
5-6: Rename / Queue
7-8: Schedule / Schedule

실행부 (9-19단계):
9-12: Register File Read (4단계!)
13-17: Execute (5단계)
18-19: Flags / Branch Check

백엔드 (20-31단계):  
20-28: Memory Access (9단계!)
29-31: Write Back (3단계)

목표: 3.8GHz 달성 (2004년)
```

#### 트레이스 캐시 (Trace Cache)
```
전통적 방식:
명령어 인출 → 해석 → 마이크로 연산 변환

Pentium 4 방식:
해석된 마이크로 연산을 캐시에 저장
분기를 포함한 실행 경로 전체를 캐시

장점:
- 복잡한 x86 해석 과정 생략
- 분기 예측 미스 시 빠른 복구

단점:
- 트레이스 캐시 미스 시 큰 페널티
- 복잡한 하드웨어
```

### ARM Cortex-A15 파이프라인

#### 15-17단계 비순차 실행
```
인출 (1-3단계):
1: Instruction Fetch 1
2: Instruction Fetch 2  
3: Instruction Decode

발행 (4-6단계):
4: Issue Queue
5: Register Rename
6: Dispatch

실행 (7-12단계):
7-9: Execute (3단계, 파이프라인별 상이)
10-12: Complete (3단계)

완료 (13-17단계):
13-15: Load/Store Unit (3단계)
16-17: Commit (2단계)

특징:
- 비순차 실행 (Out-of-order)
- 동적 분기 예측
- 3-way 슈퍼스칼라
```

---

## 📊 성능 분석과 최적화

### 파이프라인 성능 지표

#### CPI (Cycles Per Instruction)
```
이상적 CPI = 1 (완전 파이프라인)

실제 CPI = 1 + 평균 정지 사이클 수

평균 정지 사이클 = Σ(위험성 빈도 × 페널티)

예시:
- 데이터 위험성: 20% × 1사이클 = 0.2
- 제어 위험성: 15% × 2사이클 = 0.3  
- 구조적 위험성: 5% × 1사이클 = 0.05

실제 CPI = 1 + 0.2 + 0.3 + 0.05 = 1.55
```

#### 스피드업 (Speedup)
```
스피드업 = 파이프라인 없는 시간 / 파이프라인 시간

예시: 100개 명령어, 5단계 파이프라인
- 파이프라인 없음: 100 × 5 = 500 사이클
- 파이프라인 적용: 5 + 99 = 104 사이클  
- 스피드업: 500/104 ≈ 4.8배

실제로는 위험성으로 인해 더 낮음:
- CPI = 1.55인 경우: 5 + 99×1.55 ≈ 158 사이클
- 스피드업: 500/158 ≈ 3.2배
```

#### 처리량 (Throughput)
```
이상적 처리량 = 클록 주파수 / 1 (명령어/사이클)

실제 처리량 = 클록 주파수 / CPI

예시: 3GHz 프로세서, CPI = 1.5
처리량 = 3×10⁹ / 1.5 = 2×10⁹ 명령어/초 = 2 GIPS
```

### 성능 최적화 기법

#### 컴파일러 최적화

**명령어 스케줄링**:
```
최적화 전:
LW   R1, 100(R2)    # 로드
ADD  R3, R1, R4     # 바로 사용 (정지 발생)
SUB  R5, R6, R7     # 독립적 명령어

최적화 후:  
LW   R1, 100(R2)    # 로드
SUB  R5, R6, R7     # 독립적 명령어 먼저 실행
ADD  R3, R1, R4     # 로드 지연 시간 활용

결과: 정지 사이클 제거
```

**루프 언롤링 (Loop Unrolling)**:
```
원래 루프:
for (i = 0; i < 100; i++) {
    a[i] = b[i] + c[i];
}

어셈블리:
loop:
    LW   R1, 0(R2)     # b[i] 로드
    LW   R3, 0(R4)     # c[i] 로드  
    ADD  R5, R1, R3    # 덧셈
    SW   R5, 0(R6)     # a[i] 저장
    ADDI R2, R2, 4     # 포인터 증가
    ADDI R4, R4, 4
    ADDI R6, R6, 4  
    ADDI R7, R7, 1     # 카운터 증가
    BNE  R7, 100, loop # 분기

언롤링 후 (4배):
loop:
    LW   R1, 0(R2)     # b[i] 로드
    LW   R3, 0(R4)     # c[i] 로드
    LW   R8, 4(R2)     # b[i+1] 로드
    LW   R9, 4(R4)     # c[i+1] 로드
    ADD  R5, R1, R3    # a[i] 계산
    ADD  R10, R8, R9   # a[i+1] 계산
    SW   R5, 0(R6)     # a[i] 저장
    SW   R10, 4(R6)    # a[i+1] 저장
    # ... 2개 더
    ADDI R2, R2, 16    # 4개씩 처리
    ADDI R4, R4, 16
    ADDI R6, R6, 16
    ADDI R7, R7, 4
    BNE  R7, 100, loop

장점:
- 분기 명령어 4배 감소
- 로드-사용 지연 감춤
- 더 많은 병렬성 활용
```

#### 하드웨어 최적화

**분기 예측 향상**:
```
Tournament 예측기:
- 지역 예측기 (특정 분기의 히스토리)
- 전역 예측기 (모든 분기의 히스토리)  
- 선택기 (어느 예측기가 더 정확한지 판단)

예측 정확도: 95-98%
```

**더 깊은 파이프라인**:
```
트레이드오프:
- 더 깊은 파이프라인 → 더 높은 클록 주파수
- 하지만 분기 미스 페널티 증가

최적 깊이:
- 분기 빈도와 예측 정확도에 따라 결정
- 일반적으로 10-20단계가 최적
```

**슈퍼스칼라 확장**:
```
발행 폭 확장:
- 2-way → 4-way → 8-way

하지만 한계:
- 의존성으로 인한 병렬성 부족
- 하드웨어 복잡도 기하급수적 증가
- 전력 소비 급증
```

---

## 🧪 실습 및 시뮬레이션

### MIPS 파이프라인 시뮬레이터

#### SimpleScalar 설정
```bash
# MIPS 파이프라인 시뮬레이션
./sim-outorder -config mips_pipeline.cfg \
  -max:inst 1000000 \
  -ptrace ptrace.out \
  benchmark.exe

# 설정 파일 (mips_pipeline.cfg):
-fetch:ifqsize 4          # 명령어 큐 크기
-decode:width 2           # 디코딩 폭  
-issue:width 2            # 발행 폭
-commit:width 2           # 커밋 폭
-ruu:size 16             # Reorder Buffer 크기
-lsq:size 8              # Load/Store Queue 크기
```

#### 파이프라인 추적 분석
```
ptrace.out 파일 분석:

@ 1234 0x00400000 [xor]: R[8] <- 0x00000001
  - 사이클 1234에서 xor 명령어 실행
  - PC: 0x00400000
  - R8 레지스터에 0x00000001 저장

@ 1235 0x00400004 [lw]: R[9] <- 0x12345678 (D-cache miss)
  - 로드 명령어, 캐시 미스 발생
  - 추가 지연 시간 발생

성능 분석:
- CPI 계산
- 캐시 미스율  
- 분기 예측 정확도
```

### 파이프라인 위험성 실험

#### 데이터 위험성 실험
```assembly
# RAW 위험성 테스트
.text
main:
    add $t0, $t1, $t2    # $t0 = $t1 + $t2
    add $t3, $t0, $t4    # $t0 의존성 (RAW)
    add $t5, $t6, $t7    # 독립적
    add $t8, $t3, $t9    # $t3 의존성 (RAW)

# 최적화된 버전 (의존성 제거)
main_opt:
    add $t0, $t1, $t2    # $t0 = $t1 + $t2  
    add $t5, $t6, $t7    # 독립적 (먼저 실행)
    add $t3, $t0, $t4    # $t0 의존성
    add $t8, $t3, $t9    # $t3 의존성
```

#### 제어 위험성 실험
```assembly
# 분기 집약적 코드
.text
test_branches:
    li $t0, 0            # 카운터 초기화
loop:
    beq $t0, 100, end    # 분기 1
    addi $t0, $t0, 1     # 카운터 증가
    
    andi $t1, $t0, 1     # 홀짝 판별
    beq $t1, 0, even     # 분기 2
    
odd:
    sll $t2, $t0, 1      # 홀수 처리
    j next
    
even:  
    srl $t2, $t0, 1      # 짝수 처리
    
next:
    j loop               # 분기 3
    
end:
    # 종료
```

### 성능 측정 코드

#### 파이프라인 효율성 측정
```c
#include <stdio.h>
#include <time.h>

// RAW 위험성이 많은 코드
void raw_hazard_code() {
    int a = 1, b = 2, c = 3, d = 4;
    for (int i = 0; i < 1000000; i++) {
        a = b + c;     // RAW: a
        d = a * 2;     // 바로 a 사용
        b = d + 1;     // RAW: d  
        c = b - a;     // 바로 d, a 사용
    }
}

// 최적화된 코드 (의존성 최소화)
void optimized_code() {
    int a = 1, b = 2, c = 3, d = 4;
    int e = 5, f = 6, g = 7, h = 8;  // 추가 변수
    
    for (int i = 0; i < 1000000; i++) {
        a = b + c;     // 독립적
        e = f * g;     // 독립적
        d = a * 2;     // a 사용 (지연 시간 확보)
        h = e + 1;     // e 사용
        b = d + 1;     // d 사용
        c = h - a;     // h, a 사용
    }
}

int main() {
    clock_t start, end;
    
    // RAW 위험성 코드 측정
    start = clock();
    raw_hazard_code();
    end = clock();
    printf("RAW hazard code: %.2f ms\n", 
           (double)(end - start) * 1000 / CLOCKS_PER_SEC);
    
    // 최적화된 코드 측정  
    start = clock();
    optimized_code();
    end = clock();
    printf("Optimized code: %.2f ms\n",
           (double)(end - start) * 1000 / CLOCKS_PER_SEC);
    
    return 0;
}
```

#### 분기 예측 영향 측정
```c
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

// 예측 가능한 분기 (패턴이 있음)
void predictable_branches() {
    int sum = 0;
    for (int i = 0; i < 1000000; i++) {
        if (i % 4 == 0) {        // 25% 확률, 규칙적
            sum += i;
        }
    }
}

// 예측 불가능한 분기 (랜덤)  
void unpredictable_branches() {
    int sum = 0;
    srand(42);  // 일정한 시드로 재현 가능
    
    for (int i = 0; i < 1000000; i++) {
        if (rand() % 4 == 0) {   // 25% 확률, 랜덤
            sum += i;
        }
    }
}

int main() {
    clock_t start, end;
    
    // 예측 가능한 분기
    start = clock();  
    predictable_branches();
    end = clock();
    printf("Predictable branches: %.2f ms\n",
           (double)(end - start) * 1000 / CLOCKS_PER_SEC);
    
    // 예측 불가능한 분기
    start = clock();
    unpredictable_branches();  
    end = clock();
    printf("Unpredictable branches: %.2f ms\n",
           (double)(end - start) * 1000 / CLOCKS_PER_SEC);
    
    return 0;
}
```

### CPU 시뮬레이터 구현

#### 간단한 5단계 파이프라인 시뮬레이터
```python
class Pipeline:
    def __init__(self):
        self.stages = ['IF', 'ID', 'EX', 'MEM', 'WB']
        self.pipeline = [None] * 5  # 각 단계의 명령어
        self.registers = [0] * 32   # 32개 레지스터
        self.memory = [0] * 1024    # 간단한 메모리
        self.pc = 0
        self.cycle = 0
        
    def fetch(self):
        if self.pc < len(self.instructions):
            return self.instructions[self.pc]
        return None
        
    def decode(self, instruction):
        if instruction is None:
            return None
        # 명령어 파싱 (간단화)
        parts = instruction.split()
        return {
            'op': parts[0],
            'dst': int(parts[1]) if len(parts) > 1 else 0,
            'src1': int(parts[2]) if len(parts) > 2 else 0,
            'src2': int(parts[3]) if len(parts) > 3 else 0
        }
        
    def execute(self, decoded):
        if decoded is None:
            return None
        if decoded['op'] == 'ADD':
            result = self.registers[decoded['src1']] + self.registers[decoded['src2']]
            return {'op': 'ADD', 'dst': decoded['dst'], 'result': result}
        # 다른 명령어들...
        return decoded
        
    def memory_access(self, executed):
        if executed is None:
            return None
        if executed['op'] == 'LW':
            # 메모리 로드
            addr = executed['addr']
            executed['result'] = self.memory[addr]
        elif executed['op'] == 'SW':
            # 메모리 스토어
            addr = executed['addr']
            self.memory[addr] = executed['data']
        return executed
        
    def write_back(self, mem_result):
        if mem_result is None:
            return
        if 'dst' in mem_result and 'result' in mem_result:
            self.registers[mem_result['dst']] = mem_result['result']
            
    def run_cycle(self):
        # 역순으로 실행 (WB부터 IF까지)
        self.write_back(self.pipeline[4])
        self.pipeline[4] = self.memory_access(self.pipeline[3])
        self.pipeline[3] = self.execute(self.pipeline[2])
        self.pipeline[2] = self.decode(self.pipeline[1])
        self.pipeline[1] = self.fetch()
        
        if self.pipeline[1] is not None:
            self.pc += 1
            
        self.cycle += 1
        
    def print_state(self):
        print(f"Cycle {self.cycle}:")
        for i, stage in enumerate(self.stages):
            inst = self.pipeline[i]
            print(f"  {stage}: {inst if inst else 'empty'}")
        print()
```

---

## 📚 학습 가이드 및 정리

### 핵심 개념 체크리스트

#### ✅ 명령어 사이클 이해
- [ ] Fetch-Decode-Execute-Store 각 단계의 상세 동작
- [ ] 각 단계에서 사용되는 하드웨어 구성요소
- [ ] 명령어 형식과 해석 과정
- [ ] 메모리 접근과 레지스터 업데이트

#### ✅ 파이프라이닝 기본 원리  
- [ ] 파이프라이닝의 개념과 장점
- [ ] 5단계 기본 파이프라인 구조
- [ ] 파이프라인의 처리량과 지연시간
- [ ] 이상적 vs 실제 성능

#### ✅ 위험성과 해결방법
- [ ] 구조적/데이터/제어 위험성 구분
- [ ] RAW, WAR, WAW 의존성 이해
- [ ] 정지, 전달, 분기예측 해결책
- [ ] 각 해결책의 트레이드오프

#### ✅ 고급 기법
- [ ] 슈퍼스칼라의 개념과 구현
- [ ] 순차 vs 비순차 실행
- [ ] VLIW의 장단점
- [ ] 현대 프로세서의 복잡한 파이프라인

### 면접/시험 대비 문제

#### 기본 문제
1. **파이프라이닝의 장점과 단점을 설명하고, 왜 모든 CPU가 파이프라인을 사용하는지 설명하시오.**

2. **다음 명령어 시퀀스에서 발생하는 위험성을 찾고 해결방법을 제시하시오.**
   ```
   ADD R1, R2, R3
   SUB R4, R1, R5
   LW  R6, 100(R1)
   BEQ R4, R6, label
   ```

3. **5단계 파이프라인에서 10개 명령어를 실행할 때의 총 사이클 수를 계산하고, 파이프라이닝 없는 경우와 비교하시오.**

#### 심화 문제
1. **슈퍼스칼라와 VLIW의 차이점을 설명하고, 각각의 적합한 응용 분야를 제시하시오.**

2. **분기 예측의 중요성을 설명하고, 2비트 포화 카운터 예측기의 동작 과정을 상태도로 그리시오.**

3. **로드-사용 위험성이 전달(forwarding)로 해결되지 않는 이유를 설명하고, 실제 해결 방법을 제시하시오.**

#### 실무 문제  
1. **모바일 프로세서와 데스크톱 프로세서의 파이프라인 설계 차이점과 그 이유를 설명하시오.**

2. **컴파일러가 파이프라인 성능 향상을 위해 사용하는 최적화 기법들을 구체적인 예시와 함께 설명하시오.**

3. **멀티코어 환경에서 개별 코어의 파이프라인 설계 시 고려사항을 설명하시오.**

### 실습 프로젝트 추천

#### 1. 파이프라인 시뮬레이터 구현
```
난이도: 중급
목표: 5단계 파이프라인 완전 구현
기능:
- 기본 명령어 세트 (ADD, SUB, LW, SW, BEQ)
- 위험성 감지 및 해결
- 성능 통계 수집
- 시각화 기능

학습 효과:
- 파이프라인 동작 원리 완전 이해
- 위험성 해결 메커니즘 구현 경험
- 성능 분석 능력 향상
```

#### 2. 분기 예측기 구현 및 비교
```
난이도: 고급  
목표: 다양한 분기 예측기 구현 및 성능 비교
구현 대상:
- 1비트 예측기
- 2비트 포화 카운터
- gshare 예측기
- Tournament 예측기

평가 기준:
- 예측 정확도
- 하드웨어 복잡도 (비트 수)
- 다양한 벤치마크에서의 성능
```

#### 3. 컴파일러 최적화 도구
```
난이도: 고급
목표: 파이프라인 성능 향상을 위한 코드 최적화
기능:
- 명령어 스케줄링
- 루프 언롤링
- 소프트웨어 파이프라이닝
- 성능 분석 및 비교

도구:
- LLVM 기반 최적화 패스 작성
- 또는 간단한 어셈블리 변환기 구현
```

---

## 🎯 최종 정리

### 명령어 사이클 & 파이프라이닝 핵심 포인트

1. **명령어 사이클**은 모든 프로그램 실행의 기본 단위
2. **파이프라이닝**은 처리량 향상의 핵심 기법  
3. **위험성 해결**이 실제 성능을 결정
4. **고급 기법들**은 한계를 극복하는 방법
5. **컴파일러와 하드웨어**의 협력이 중요

### 학습 로드맵

#### 1단계: 기초 다지기 (2-3주)
- [ ] 명령어 사이클 4단계 완전 이해
- [ ] 기본 파이프라인 개념과 동작
- [ ] 간단한 성능 계산

#### 2단계: 위험성 마스터 (3-4주)
- [ ] 3가지 위험성 완전 이해
- [ ] 해결 방법들의 장단점 비교
- [ ] 실제 예시로 위험성 분석

#### 3단계: 고급 기법 (4-5주)
- [ ] 슈퍼스칼라와 VLIW 이해
- [ ] 현대 프로세서 파이프라인 분석
- [ ] 성능 최적화 기법

#### 4단계: 실습과 응용 (3-4주)
- [ ] 시뮬레이터 구현 또는 사용
- [ ] 실제 코드 최적화 실험
- [ ] 성능 측정과 분석

### 실무 활용 팁

1. **프로그래밍 시 고려사항**:
   - 데이터 의존성 최소화
   - 예측 가능한 분기 패턴 사용
   - 캐시 친화적 코드 작성

2. **성능 최적화 순서**:
   - 프로파일링으로 병목 지점 파악
   - 알고리즘 레벨 최적화 우선
   - 마이크로 최적화는 마지막

3. **하드웨어 이해의 중요성**:
   - CPU 아키텍처별 특성 파악
   - 컴파일러 최적화 옵션 활용
   - 벤치마킹과 측정 도구 사용

