# AI 모델 활용

AI 모델의 연산을 모두 양자화하면 모델 크기가 줄어드는 것 외에 어떤 장점이 있을까?

AI 모델의 값들이 모두 양자화 되었음에도 불구하고, 연산과정을 양자화할 때 추가로 필요한 작업은 무엇일까?

연산과정의 양자화를 위한 대표적 기법(실수 파트만 모으기, 비트쉬프팅)은 어떻게 작동할까?

> 3가지 질문에 대답 가능하면 훌륭

AWS 같은 클라우드 이용한 AI는 인터넷 끊기면 막대한 피해 발생
온디바이스 AI는 개인정보 해킹이나 보안상 안전, 클라우드 이용하지 않으므로 위와같은 사례 발생 x 의료쪽에 활용가능

AI 가속기 : 신경망 연산에 특화되어서 빠름, 실수연산 과감하게 포기하고 정수 연산만 함
edge TPU, NPU

한가지 비트로는 0, 1표현, N비트 있으면 2의 N제곱만큼 정보 표현

실수: 32비트 사용. 2의 32제곱으로 표현
실수를 포기하고 8비트만 사용 256개의 정수사용 -> 연산속도 상당히 빨라짐
정수 x 정수는 실수 x 실수보다 연산이 아주 빠름

일반 양자화 : r이라는 실수 값을 q라는 정수로 표현하고 싶다!
-> 실수는 무한한데, 이를 나타내기는 불가능하니 유한한 관심 범위를 지정 